# Chat Completion with Local Server

This project demonstrates how to use the OpenAI API for chat completions with a local server setup. It allows users to input prompts via command-line arguments and receive responses from a specified model.

## Prerequisites

- Python 3.x
- `mlx-omni-server` installed

## Installation

1. Install the `mlx-omni-server`:
   ```bash
   pip install mlx-omni-server
   ```

2. Start the local server:
   ```bash
   mlx-omni-server
   ```

## Usage

Run the script from the command line, providing a prompt as an argument:

```bash
uv run main.py "What is the capital of Argentina?"
```

Feel free to modify any sections to better fit your project's specifics!